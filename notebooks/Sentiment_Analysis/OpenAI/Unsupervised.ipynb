{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../../../data/Fine-Tuning/Updated_Pretraining_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating JSONL file from table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test.jsonl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a function to create the message format for each row\n",
    "def create_message(row):\n",
    "    system_content = \"This model is trained to analyze the sentiment of news articles concerning the LNG market and predict their impact on the LNG index's opening price and volatility for the following day. Please provide estimates for the expected return (ranging from -10.0 to +10.0), the volatility effect (ranging from -10.0 to +10.0), and the duration of the impact (scaled from 0 to 10, where 0 represents no impact and 10 represents a permanent impact). Include a comment explaining the rationale behind your predictions. Consider long-term market trends, seasonal variations, global supply-demand dynamics, and macroeconomic factors that might influence LNG prices and market behavior.\"\n",
    "    \n",
    "    user_content = {\n",
    "        \"date\": row[\"Timestamp\"],\n",
    "        \"title\": row[\"Title\"],\n",
    "        \"summary\": row[\"Summary\"],\n",
    "        \"price\": row[\"last_price\"],\n",
    "        \"vol_annual\": row[\"volatility_annual\"]\n",
    "    }\n",
    "\n",
    "    assistant_content = {\n",
    "        \"return\": row[\"T+3 return_normalized\"],\n",
    "        \"vol\": row[\"volatility_annual_normalized\"],\n",
    "        \"duration\": row[\"duration_estimated\"],\n",
    "        \"comment\": \"\"\n",
    "    }\n",
    "\n",
    "    message = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(user_content)},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(assistant_content)}\n",
    "        ]\n",
    "    }\n",
    "    return message\n",
    "\n",
    "# Generate messages for each row in the dataframe\n",
    "messages = data.apply(create_message, axis=1).tolist()\n",
    "\n",
    "# Write messages to a JSONL file\n",
    "jsonl_file_path = './LNG_unsupervised_full.jsonl'\n",
    "with open(jsonl_file_path, 'w') as outfile:\n",
    "    for message in messages:\n",
    "        json.dump(message, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "jsonl_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading JSONL file to OpenAI for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv(\"OpenAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"LNG_unsupervised.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the fine tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = os.getenv(\"Unsupervised_Training_File\")\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_key = os.getenv(\"Unsupervised_Fine_Tuning_Job\")\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(job_key)\n",
    "\n",
    "# Cancel a job\n",
    "# client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "# client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-abc123\", limit=10)\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "# client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to genrate output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='{\"return\": -3.194664175893563, \"vol\": -9.367349168765628, \"duration\": 7.555806724871983, \"comment\": \"\"}', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "model_id = os.getenv(\"Unsupervised_Fine_Tuning_Model\")\n",
    "completion = client.chat.completions.create(\n",
    "  model=model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This model is trained to analyze the sentiment of news articles concerning the LNG market and predict their impact on the LNG index's opening price and volatility for the following day. Please provide estimates for the expected return (ranging from -10.0 to +10.0), the volatility effect (ranging from -10.0 to +10.0), and the duration of the impact (scaled from 0 to 10, where 0 represents no impact and 10 represents a permanent impact). Include a comment explaining the rationale behind your predictions. Consider long-term market trends, seasonal variations, global supply-demand dynamics, and macroeconomic factors that might influence LNG prices and market behavior.\"},\n",
    "    {\"role\": \"user\", \"content\": \"{\\\"date\\\": \\\"2022-07-19\\\", \\\"title\\\": \\\"Russian Gas Supplies to Europe Aren\\\\u2019t Expected to Restart\\\", \\\"summary\\\": \\\"Europe is working on contingency plans for the possibility that the Nord Stream pipeline won\\\\u2019t return to operation.\\\", \\\"price\\\": 38.372, \\\"vol_annual\\\": 9.020759401473269}\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "This model is trained to analyze the sentiment of news articles concerning the LNG market and predict the impact on the LNG index's price. Predictions are made based on the news content, current price, and current volatility on the provided date. The model outputs include the direction of the price movement (true for higher, false for lower), the magnitude of this change (ranging from 0.0 to 10.0), and a comment explaining the rationale behind these predictions. The results are provided in the following JSON format:\n",
    "{\n",
    "  \"direction\": \"boolean\",\n",
    "  \"magnitude\": \"float\",\n",
    "  \"comment\": \"string\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "def main():\n",
    "    \n",
    "    api_key = os.getenv('OpenAI_API_KEY')\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # Load model ID from environment variable\n",
    "    model_id = os.getenv(\"Unsupervised_Fine_Tuning_Model\")\n",
    "    \n",
    "    # Path to the JSONL input file\n",
    "    file_path = './LNG_unsupervised_full.jsonl'\n",
    "    \n",
    "    # Path for the output file\n",
    "    output_path = './output/unsupervised_outputs_gp4turbo_05010120.txt'\n",
    "    \n",
    "    # Prepare the system message (constant part of the prompt)\n",
    "    # system_message_content = \"This model is trained to analyze the sentiment of news articles concerning the LNG market and predict their impact on the LNG index's opening price and volatility for the following day. Please provide estimates for the expected return (ranging from -10.0 to +10.0), the volatility effect (ranging from -10.0 to +10.0), and the duration of the impact (scaled from 0 to 10, where 0 represents no impact and 10 represents a permanent impact). Include a comment explaining the rationale behind your predictions. Consider long-term market trends, seasonal variations, global supply-demand dynamics, and macroeconomic factors that might influence LNG prices and market behavior.\"\n",
    "    system_message_content = \"This model is trained to analyze the sentiment of news articles concerning the LNG market and predict the impact on the LNG index's price. Predictions are made based on the news content, current price, and current volatility on the provided date. The model outputs include the direction of the price movement (true for higher, false for lower), the magnitude of this change (ranging from 0.0 to 10.0), and a comment explaining the rationale behind these predictions. The results are provided in the following JSON format: {\\\"direction\\\": \\\"boolean\\\", \\\"magnitude\\\": \\\"float\\\",\\\"comment\\\": \\\"string\\\"}\"\n",
    "\n",
    "    # Open the input file and output file\n",
    "    with open(file_path, 'r') as infile, open(output_path, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            # Parse the JSON line\n",
    "            data = json.loads(line)\n",
    "            user_message = json.loads(data['messages'][1]['content'])  # Parse the user message content as JSON\n",
    "            user_message_content = data['messages'][1]['content']\n",
    "\n",
    "            # print(user_message_content)\n",
    "            \n",
    "            # Create the API call with messages\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message_content},\n",
    "                    {\"role\": \"user\", \"content\": user_message_content}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                top_p=0.5,\n",
    "            )\n",
    "            \n",
    "            # Extract date from the user message\n",
    "            date = user_message['date']\n",
    "            \n",
    "            # Write the model's response to the output file including the date\n",
    "            outfile.write(f\"{date}: {str(completion.choices[0].message)}\\n\")\n",
    "            # break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the file\n",
    "file_path = './output/unsupervised_outputs_04302300.txt'\n",
    "\n",
    "# Read and parse the data\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        date_part, message_part = line.split(': ', 1)\n",
    "        message_json = json.loads(message_part.split(\"ChatCompletionMessage(content='\")[1].split(\"', role='assistant'\")[0])\n",
    "        data.append({\n",
    "            'Date': date_part,\n",
    "            'Return': message_json['return'],\n",
    "            'Vol': message_json['vol'],\n",
    "            'Duration': message_json['duration']\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('./output/unsupervised_outputs_04302300.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the file\n",
    "file_path = './output/unsupervised_outputs_gp4turbo_05010120.txt'\n",
    "\n",
    "# def extract_json(line):\n",
    "#     start = line.find(\"content='\") + len(\"content='\")\n",
    "#     end = line.rfind(\"', role='assistant'\")\n",
    "#     json_str = line[start:end]\n",
    "#     # Fix for JSON decoding errors due to improper escapes\n",
    "#     json_str = json_str.replace(\"\\\\'\", \"'\").replace('\\\\\"', '\"')\n",
    "#     return json.loads(json_str)\n",
    "\n",
    "\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.split\n",
    "        break\n",
    "        # if line.strip():  # Ensuring the line is not empty\n",
    "        #     date_part, rest = line.split(': ', 1)\n",
    "            # try:\n",
    "            #     message_json = extract_json(rest)\n",
    "            #     data.append({\n",
    "            #         'Date': date_part,\n",
    "            #         'Direction': message_json['direction'],\n",
    "            #         'Magnitude': message_json['magnitude'],\n",
    "            #         'Comment': message_json['comment']\n",
    "            #     })\n",
    "            # except json.JSONDecodeError as e:\n",
    "            #     print(f\"Failed to decode JSON: {e}\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_file_path = './output/unsupervised_outputs_gp4turbo_05010120.csv'\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './output/unsupervised_outputs_gp4turbo_05010120.txt'\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        date = line.split(':')[0]\n",
    "        direction = line.split(\"\\\"direction\\\": \")[1].split(',')[0]\n",
    "        magnitude = line.split(\"\\\"magnitude\\\": \")[1].split(',')[0].replace('\\\"', '')\n",
    "        comment = line.split(\"\\\"comment\\\": \")[1].split('}')[0].replace('\\\"', '')\n",
    "        data.append({'Date': date, 'Direction': direction, 'Magnitude': magnitude, 'Comment': comment})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_file_path = './output/unsupervised_outputs_gp4turbo_05010120.csv'\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
